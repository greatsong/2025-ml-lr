import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

# ë¶„ë¥˜ ëª¨ë¸
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier

# íšŒê·€ ëª¨ë¸
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor

st.set_page_config(page_title="ML êµìœ¡ìš© ì›¹ì•±: ë¶„ë¥˜+íšŒê·€+EDA", layout="wide")

# ===============================
# ì‚¬ì´ë“œë°”: êµìœ¡ ì•ˆë‚´
# ===============================
with st.sidebar:
    st.title("ğŸ“ êµìœ¡ìš© ì•ˆë‚´")
    st.markdown("""
**í•™ìŠµ íë¦„**
1) ìƒë‹¨ íƒ­ì—ì„œ **ë¶„ë¥˜(ì•„ì´ë¦¬ìŠ¤)** ë˜ëŠ” **íšŒê·€(ê¸°ì˜¨ ì˜ˆì¸¡)** ì„ íƒ  
2) **ë°ì´í„° ì†ŒìŠ¤**: ë‚´ì¥ ìƒ˜í”Œ ë˜ëŠ” CSV ì—…ë¡œë“œ (ê¸°ì˜¨ CSVëŠ” cp949 ê¶Œì¥)  
3) **EDA**(ìš”ì•½/ë¶„í¬/ê´€ê³„/ìƒê´€) ë¨¼ì € ë³´ê¸°  
4) **ëª¨ë¸/ì˜µì…˜** ê³ ë¥´ê³  **í•™ìŠµ/í‰ê°€**

**TIP**  
- EDAë¡œ ë°ì´í„°ì˜ íŒ¨í„´Â·ì´ìƒì¹˜Â·ìŠ¤ì¼€ì¼ì„ í™•ì¸í•˜ì„¸ìš”.  
- ì„±ëŠ¥ì´ ë‚®ë‹¤ë©´: íŠ¹ì„± ì„ íƒ, ìŠ¤ì¼€ì¼ ì¡°ì •, ëª¨ë¸ ë³€ê²½ì„ ì‹œë„!
    """)

st.title("ğŸ§ª ê°„ë‹¨í•œ ë¨¸ì‹ ëŸ¬ë‹ êµìœ¡ìš© ì›¹ì•± (Streamlit Cloud)")

# ===============================
# ìœ í‹¸ í•¨ìˆ˜
# ===============================
def smart_read_csv(file_or_path, skip_top_rows=0):
    """cp949 â†’ utf-8-sig â†’ utf-8 â†’ euc-kr ìˆœìœ¼ë¡œ ì‹œë„, ìƒë‹¨ Ní–‰ ìŠ¤í‚µ ì§€ì›"""
    encodings = ["cp949", "utf-8-sig", "utf-8", "euc-kr"]
    last_err = None
    for enc in encodings:
        try:
            return pd.read_csv(
                file_or_path,
                encoding=enc,
                skiprows=range(skip_top_rows) if skip_top_rows > 0 else None
            )
        except Exception as e:
            last_err = e
            continue
    # ë§ˆì§€ë§‰ ì‹œë„ (ì¸ì½”ë”© ì§€ì • ì—†ì´)
    return pd.read_csv(
        file_or_path,
        skiprows=range(skip_top_rows) if skip_top_rows > 0 else None
    )

def render_eda(df, title_suffix=""):
    st.subheader(f"ğŸ” EDA(íƒìƒ‰ì  ë°ì´í„° ë¶„ì„){' - ' + title_suffix if title_suffix else ''}")

    with st.expander("1) ë°ì´í„° ê°œìš” (í–‰/ì—´, íƒ€ì…, ê²°ì¸¡ì¹˜)"):
        c1, c2, c3 = st.columns([1,1,1])
        with c1:
            st.metric("í–‰(Row) ìˆ˜", f"{len(df):,}")
        with c2:
            st.metric("ì—´(Column) ìˆ˜", f"{df.shape[1]:,}")
        with c3:
            num_cols = df.select_dtypes(include=np.number).shape[1]
            st.metric("ìˆ«ìí˜• íŠ¹ì„± ìˆ˜", f"{num_cols:,}")

        st.write("**ë°ì´í„° íƒ€ì…**")
        st.dataframe(pd.DataFrame(df.dtypes, columns=["dtype"]))

        st.write("**ê²°ì¸¡ì¹˜ í˜„í™©**")
        miss = df.isna().sum()
        miss_df = miss[miss>0].to_frame("missing_count")
        if miss_df.empty:
            st.success("ê²°ì¸¡ì¹˜ ì—†ìŒ âœ…")
        else:
            st.warning("ê²°ì¸¡ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ ì—´ì„ í™•ì¸í•˜ì„¸ìš”.")
            st.dataframe(miss_df)

    with st.expander("2) ë¯¸ë¦¬ë³´ê¸°(Head/Tail)"):
        st.write("**Head(ìƒìœ„ 5í–‰)**")
        st.dataframe(df.head())
        st.write("**Tail(í•˜ìœ„ 5í–‰)**")
        st.dataframe(df.tail())

    with st.expander("3) ìˆ«ìí˜• í†µê³„ ìš”ì•½"):
        num_df = df.select_dtypes(include=np.number)
        if not num_df.empty:
            st.dataframe(num_df.describe().T)
        else:
            st.info("ìˆ«ìí˜• ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    with st.expander("4) ë¶„í¬ íƒìƒ‰(íˆìŠ¤í† ê·¸ë¨)"):
        num_cols = df.select_dtypes(include=np.number).columns.tolist()
        if num_cols:
            col = st.selectbox("íˆìŠ¤í† ê·¸ë¨ìœ¼ë¡œ ë³¼ ìˆ«ìí˜• íŠ¹ì„± ì„ íƒ", num_cols, key=f"hist_{title_suffix}")
            bins = st.slider("êµ¬ê°„ ê°œìˆ˜(Bins)", 10, 60, 30, key=f"bins_{title_suffix}")
            chart = alt.Chart(df).mark_bar().encode(
                x=alt.X(alt.repeat("column"), type='quantitative', bin=alt.Bin(maxbins=bins)),
                y='count()'
            ).properties(width=500, height=300).repeat(column=[col])
            st.altair_chart(chart, use_container_width=True)
        else:
            st.info("ìˆ«ìí˜• ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    with st.expander("5) ì‚°ì ë„(ë‘ íŠ¹ì„± ê´€ê³„)"):
        num_cols = df.select_dtypes(include=np.number).columns.tolist()
        if len(num_cols) >= 2:
            x = st.selectbox("Xì¶•", num_cols, key=f"x_{title_suffix}")
            y = st.selectbox("Yì¶•", [c for c in num_cols if c != x], key=f"y_{title_suffix}")
            color_col = st.selectbox("ìƒ‰ìƒ ê¸°ì¤€(ì„ íƒ)", ["(ì—†ìŒ)"] + df.columns.tolist(), key=f"color_{title_suffix}")
            enc = {"x": alt.X(x, type='quantitative'), "y": alt.Y(y, type='quantitative')}
            if color_col != "(ì—†ìŒ)":
                enc["color"] = color_col
            chart = alt.Chart(df).mark_circle(size=60, opacity=0.6).encode(**enc).properties(height=350)
            st.altair_chart(chart, use_container_width=True)
        else:
            st.info("ì‚°ì ë„ë¥¼ ê·¸ë¦¬ë ¤ë©´ ìµœì†Œ 2ê°œì˜ ìˆ«ìí˜• ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    with st.expander("6) ìƒê´€ê´€ê³„(ìˆ«ìí˜•) íˆíŠ¸ë§µ"):
        num_df = df.select_dtypes(include=np.number)
        if num_df.shape[1] >= 2:
            corr = num_df.corr(numeric_only=True)
            corr_reset = corr.reset_index().melt('index')
            corr_reset.columns = ['feature_x', 'feature_y', 'corr']
            heat = alt.Chart(corr_reset).mark_rect().encode(
                x=alt.X('feature_x:O', sort=None),
                y=alt.Y('feature_y:O', sort=None),
                tooltip=['feature_x', 'feature_y', alt.Tooltip('corr:Q', format=".2f")],
                color=alt.Color('corr:Q', scale=alt.Scale(domain=[-1,1]))
            ).properties(height=400)
            st.altair_chart(heat, use_container_width=True)
        else:
            st.info("ìˆ«ìí˜• ì»¬ëŸ¼ì´ 2ê°œ ì´ìƒì¼ ë•Œ ìƒê´€ íˆíŠ¸ë§µì„ ê·¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

def build_xy(df, target_col):
    X = df.drop(columns=[target_col])
    y = df[target_col]
    return X, y

def make_preprocessor(X, scale_numeric=True, onehot_categorical=True):
    numeric_features = X.select_dtypes(include=np.number).columns.tolist()
    categorical_features = X.select_dtypes(exclude=np.number).columns.tolist()

    transformers = []
    if numeric_features:
        if scale_numeric:
            transformers.append(("num", Pipeline(steps=[
                ("imputer", SimpleImputer(strategy="median")),
                ("scaler", StandardScaler())
            ]), numeric_features))
        else:
            transformers.append(("num", Pipeline(steps=[
                ("imputer", SimpleImputer(strategy="median"))
            ]), numeric_features))

    if categorical_features and onehot_categorical:
        transformers.append(("cat", Pipeline(steps=[
            ("imputer", SimpleImputer(strategy="most_frequent")),
            ("onehot", OneHotEncoder(handle_unknown="ignore"))
        ]), categorical_features))

    if not transformers:
        return None

    pre = ColumnTransformer(transformers=transformers, remainder="drop")
    return pre

# ===============================
# ë‚´ì¥ ë°ì´í„° ë¡œë”
# ===============================
def load_builtin_iris():
    from sklearn.datasets import load_iris
    data = load_iris(as_frame=True)
    df = data.frame.copy()
    df["species"] = df["target"].map(dict(enumerate(data.target_names)))
    return df, "species"

def load_temperature_from_any(skip_top_rows=7):
    """data/daily_temp.csv â†’ daily_temp.csv â†’ ì—†ìœ¼ë©´ ì‹œë®¬ë ˆì´ì…˜ ìƒì„±
       - cp949 ìš°ì„ , ìƒë‹¨ Ní–‰ ìŠ¤í‚µ, date íŒŒì‹± ì‹œë„
    """
    import os
    candidates = ["data/daily_temp.csv", "daily_temp.csv"]
    for path in candidates:
        if os.path.exists(path):
            df = smart_read_csv(path, skip_top_rows)
            if "date" in df.columns:
                try:
                    df["date"] = pd.to_datetime(df["date"], errors="coerce")
                except Exception:
                    pass
            return df

    # ì‹œë®¬ë ˆì´ì…˜ (êµìœ¡ìš©)
    rng = np.random.default_rng(42)
    days = pd.date_range("2024-01-01", periods=365, freq="D")
    day_of_year = np.arange(365)
    base = 15 + 10*np.sin(2*np.pi*(day_of_year/365))  # ê³„ì ˆì„±
    weekday = [d.weekday() for d in days]
    weekday_effect = np.array([0,0.3,0.2,0.1,0,-0.1,-0.2])[weekday]
    noise = rng.normal(0, 1.5, size=365)
    temp = base + weekday_effect + noise
    df = pd.DataFrame({
        "date": days,
        "temp": temp.round(2),
        "humidity": np.clip(60 + 10*np.sin(2*np.pi*(day_of_year/365+0.1)) + rng.normal(0, 3, 365), 30, 95).round(1),
        "wind": np.clip(2 + rng.normal(0, 1, 365), 0, None).round(2),
    })
    return df

# ===============================
# ê²°ì¸¡ì¹˜ ì²˜ë¦¬
# ===============================
def apply_missing_strategy(df, target_col=None, strategy="auto"):
    """
    strategy: auto | time | linear | ffill | bfill | median | drop
    - auto(ê¶Œì¥): date ì¡´ì¬í•˜ë©´ 'time', ì—†ìœ¼ë©´ ìˆ˜ì¹˜=median, ë²”ì£¼=ìµœë¹ˆê°’
    - time: date ê¸°ì¤€ ì •ë ¬ í›„ ì‹œê°„ë³´ê°„ â†’ ë‚¨ì€ ê²°ì¸¡ ffill/bfill
    - linear: ìˆ˜ì¹˜í˜• ì„ í˜•ë³´ê°„ â†’ ë‚¨ì€ ê²°ì¸¡ ffill/bfill, ë²”ì£¼=ìµœë¹ˆê°’
    - ffill/bfill: ë‹¨ìˆœ ì „/í›„ë°© ì±„ì›€
    - median: ìˆ˜ì¹˜=ì¤‘ì•™ê°’, ë²”ì£¼=ìµœë¹ˆê°’
    - drop: ê²°ì¸¡ í¬í•¨ í–‰ ì‚­ì œ
    """
    df = df.copy()

    # date íŒŒì‹± ë³´ì •
    if "date" in df.columns and not np.issubdtype(df["date"].dtype, np.datetime64):
        try:
            df["date"] = pd.to_datetime(df["date"], errors="coerce")
        except Exception:
            pass

    # ìë™ ê·œì¹™ ê²°ì •
    if strategy == "auto":
        if "date" in df.columns and df["date"].notna().any():
            strategy = "time"
        else:
            strategy = "median"

    num_cols = df.select_dtypes(include=np.number).columns.tolist()
    cat_cols = df.select_dtypes(exclude=np.number).columns.tolist()

    if strategy == "time" and "date" in df.columns and df["date"].notna().any():
        df = df.sort_values("date")
        if num_cols:
            try:
                # ì‹œê°„ë³´ê°„: ì¸ë±ìŠ¤ë¥¼ ì‹œê°„ìœ¼ë¡œ ì„¤ì • í›„ ë³´ê°„í•˜ëŠ” ì ‘ê·¼
                df = df.set_index("date")
                df[num_cols] = df[num_cols].interpolate(method="time")
                df[num_cols] = df[num_cols].ffill().bfill()
                df = df.reset_index()
            except Exception:
                # ì‹¤íŒ¨ ì‹œ ì¼ë°˜ ë³´ê°„
                df[num_cols] = df[num_cols].interpolate()
                df[num_cols] = df[num_cols].ffill().bfill()
        # ë²”ì£¼í˜• ìµœë¹ˆê°’
        for c in cat_cols:
            if df[c].isna().any():
                mode = df[c].mode(dropna=True)
                if not mode.empty:
                    df[c].fillna(mode.iloc[0], inplace=True)

    elif strategy == "linear":
        if num_cols:
            df[num_cols] = df[num_cols].interpolate()
            df[num_cols] = df[num_cols].ffill().bfill()
        for c in cat_cols:
            if df[c].isna().any():
                mode = df[c].mode(dropna=True)
                if not mode.empty:
                    df[c].fillna(mode.iloc[0], inplace=True)

    elif strategy == "ffill":
        df = df.ffill()

    elif strategy == "bfill":
        df = df.bfill()

    elif strategy == "median":
        for c in num_cols:
            if df[c].isna().any():
                med = df[c].median()
                df[c].fillna(med, inplace=True)
        for c in cat_cols:
            if df[c].isna().any():
                mode = df[c].mode(dropna=True)
                if not mode.empty:
                    df[c].fillna(mode.iloc[0], inplace=True)

    elif strategy == "drop":
        df = df.dropna()

    return df

# ===============================
# íƒ­: ë¶„ë¥˜ / íšŒê·€
# ===============================
tab1, tab2 = st.tabs(["ğŸŒ¸ ë¶„ë¥˜: ì•„ì´ë¦¬ìŠ¤", "ğŸŒ¤ï¸ íšŒê·€: ê¸°ì˜¨ ì˜ˆì¸¡"])

# -------------------------------
# TAB 1: ë¶„ë¥˜(ì•„ì´ë¦¬ìŠ¤)
# -------------------------------
with tab1:
    st.header("ğŸŒ¸ ì•„ì´ë¦¬ìŠ¤ í’ˆì¢… ë¶„ë¥˜ (Classification)")

    src = st.radio("ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ", ["ë‚´ì¥(ì•„ì´ë¦¬ìŠ¤)", "CSV ì—…ë¡œë“œ"], horizontal=True, key="cls_src")
    if src == "CSV ì—…ë¡œë“œ":
        up = st.file_uploader("CSV ì—…ë¡œë“œ(íƒ€ê¹ƒ í¬í•¨)", type=["csv"], key="cls_up")
        if up:
            df = smart_read_csv(up, skip_top_rows=0)
            target_col = st.selectbox("íƒ€ê¹ƒ(ë¶„ë¥˜í•  ì •ë‹µ) ì»¬ëŸ¼ ì„ íƒ", options=df.columns, key="cls_target")
        else:
            st.info("CSVë¥¼ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ë¯¸ë¦¬ë³´ê¸°/EDAê°€ í‘œì‹œë©ë‹ˆë‹¤. (ë¯¸ì—…ë¡œë“œ ì‹œ ë‚´ì¥ ì‚¬ìš©)")
            df, target_col = load_builtin_iris()
    else:
        df, target_col = load_builtin_iris()

    render_eda(df, "ë¶„ë¥˜")

    st.subheader("âš™ï¸ ëª¨ë¸ ì„¤ì • & í•™ìŠµ")
    with st.expander("êµìˆ˜ì ì„¤ëª…: ë¶„ë¥˜ë€?", expanded=True):
        st.markdown("""
**ë¶„ë¥˜(Classification)**ëŠ” ë°ì´í„°ê°€ ì–´ë–¤ **ë²”ì£¼(í´ë˜ìŠ¤)**ì— ì†í•˜ëŠ”ì§€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¬¸ì œì…ë‹ˆë‹¤.  
ì˜ˆ) ê½ƒì˜ ê¸¸ì´/ë„ˆë¹„ë¡œ **í’ˆì¢…**ì„ ë§íˆê¸°.
        """)

    X, y = build_xy(df, target_col)

    c1, c2, c3 = st.columns([1,1,1])
    with c1:
        test_size = st.slider("í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨", 0.1, 0.4, 0.2, step=0.05, key="cls_test")
    with c2:
        scale_num = st.checkbox("ìˆ«ìí˜• ìŠ¤ì¼€ì¼ë§(StandardScaler)", True, key="cls_scale")
    with c3:
        onehot_cat = st.checkbox("ë¬¸ìí˜• ì›-í•«ì¸ì½”ë”©", True, key="cls_ohe")

    model_name = st.selectbox("ëª¨ë¸ ì„ íƒ", ["LogisticRegression", "KNN", "RandomForest"], key="cls_model")

    if model_name == "LogisticRegression":
        C = st.slider("ì •ê·œí™” ì„¸ê¸°(C, ì‘ì„ìˆ˜ë¡ ê°•í•¨)", 0.01, 3.0, 1.0, 0.01, key="cls_C")
        clf = LogisticRegression(max_iter=1000, C=C)
    elif model_name == "KNN":
        k = st.slider("ì´ì›ƒ ìˆ˜(k)", 1, 30, 5, key="cls_k")
        clf = KNeighborsClassifier(n_neighbors=k)
    else:
        n = st.slider("íŠ¸ë¦¬ ê°œìˆ˜", 50, 500, 200, 50, key="cls_n")
        depth = st.slider("ìµœëŒ€ ê¹Šì´(0=ì œí•œì—†ìŒ)", 0, 20, 0, key="cls_depth")
        clf = RandomForestClassifier(
            n_estimators=n,
            max_depth=None if depth==0 else depth,
            random_state=42
        )

    pre = make_preprocessor(X, scale_numeric=scale_num, onehot_categorical=onehot_cat)
    pipe = Pipeline([("pre", pre), ("model", clf)]) if pre is not None else Pipeline([("model", clf)])

    if st.button("ğŸŸ¢ í•™ìŠµ/í‰ê°€ ì‹¤í–‰", key="cls_train"):
        from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42, stratify=y
        )
        pipe.fit(X_train, y_train)
        y_pred = pipe.predict(X_test)

        acc = accuracy_score(y_test, y_pred)
        st.metric("ì •í™•ë„(Accuracy)", f"{acc*100:.2f}%")

        # í˜¼ë™í–‰ë ¬
        cm = confusion_matrix(y_test, y_pred)
        cm_df = pd.DataFrame(cm, index=[f"true_{c}" for c in np.unique(y)],
                                columns=[f"pred_{c}" for c in np.unique(y)])
        st.write("**í˜¼ë™í–‰ë ¬(Confusion Matrix)**")
        cm_long = cm_df.reset_index().melt("index")
        cm_long.columns = ["true", "pred", "count"]
        heat = alt.Chart(cm_long).mark_rect().encode(
            x="pred:O", y="true:O", color=alt.Color("count:Q"),
            tooltip=["true","pred","count"]
        ).properties(height=300)
        st.altair_chart(heat, use_container_width=True)

        # ë¶„ë¥˜ ë¦¬í¬íŠ¸(í‘œ)
        st.write("**ë¶„ë¥˜ ë¦¬í¬íŠ¸ (Precision/Recall/F1)**")
        rep = classification_report(y_test, y_pred, output_dict=True)
        st.dataframe(pd.DataFrame(rep).T)

# -------------------------------
# TAB 2: íšŒê·€(ê¸°ì˜¨ ì˜ˆì¸¡)
# -------------------------------
with tab2:
    st.header("ğŸŒ¤ï¸ ê¸°ì˜¨ ì˜ˆì¸¡ (Regression)")

    st.markdown("**CSV ìƒë‹¨ ë¶ˆí•„ìš” í–‰ ìŠ¤í‚µ ë° ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì˜µì…˜**")
    skip_n = st.slider("ìƒë‹¨ ìŠ¤í‚µí•  í–‰ ìˆ˜", 0, 20, 7,
                       help="ìš”ì²­ì‚¬í•­: 1~7í–‰ì€ ë¶ˆí•„ìš”í•˜ë¯€ë¡œ ê¸°ë³¸ 7í–‰ ìŠ¤í‚µ")
    miss_strategy = st.selectbox(
        "ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì „ëµ",
        ["auto(ê¶Œì¥)", "time(ì‹œê°„ë³´ê°„)", "linear(ì„ í˜•ë³´ê°„)", "ffill(ì „ë°©ì±„ì›€)", "bfill(í›„ë°©ì±„ì›€)", "median(ì¤‘ì•™ê°’ ëŒ€ì¹˜)", "drop(ê²°ì¸¡í–‰ ì‚­ì œ)"],
        index=0
    )
    miss_strategy_key = miss_strategy.split("(")[0]

    src = st.radio("ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ", ["ë‚´ì¥(ê¸°ì˜¨/ì‹œë®¬ë ˆì´ì…˜ ë˜ëŠ” data/daily_temp.csv)", "CSV ì—…ë¡œë“œ"], horizontal=True, key="reg_src")
    if src == "CSV ì—…ë¡œë“œ":
        up = st.file_uploader("CSV ì—…ë¡œë“œ(íƒ€ê¹ƒ í¬í•¨) - cp949 ê¶Œì¥", type=["csv"], key="reg_up")
        if up:
            raw = smart_read_csv(up, skip_top_rows=skip_n)
        else:
            st.info("CSVë¥¼ ì—…ë¡œë“œí•˜ë©´ ë¯¸ë¦¬ë³´ê¸°/EDAê°€ í‘œì‹œë©ë‹ˆë‹¤. (ë¯¸ì—…ë¡œë“œ ì‹œ ë‚´ì¥/ì‹œë®¬ë ˆì´ì…˜ ì‚¬ìš©)")
            raw = load_temperature_from_any(skip_top_rows=skip_n)
    else:
        raw = load_temperature_from_any(skip_top_rows=skip_n)

    # date íŒŒì‹± ì‹œë„
    if "date" in raw.columns:
        try:
            raw["date"] = pd.to_datetime(raw["date"], errors="coerce")
        except Exception:
            pass

    # íƒ€ê¹ƒ ìë™ íƒìƒ‰(ì¼ë°˜ì ì¸ ì´ë¦„ ìš°ì„ )
    target_candidates = [c for c in ["temp", "temperature", "target", "y"] if c in raw.columns]
    if target_candidates:
        target_reg = target_candidates[0]
    else:
        target_reg = st.selectbox("íƒ€ê¹ƒ(ì˜ˆì¸¡í•  ê°’) ì»¬ëŸ¼ ì„ íƒ", options=raw.columns, key="reg_target_sel")

    # ê²°ì¸¡ì¹˜ ì „/í›„ ë¹„êµ
    st.caption("ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì „/í›„ ë¹„êµ")
    c_before = int(raw.isna().sum().sum())
    st.write(f"â€¢ ì²˜ë¦¬ ì „ ê²°ì¸¡ì¹˜ ì´í•©: **{c_before}**")

    df_reg = apply_missing_strategy(raw, target_col=target_reg, strategy=miss_strategy_key)
    c_after = int(df_reg.isna().sum().sum())
    st.write(f"â€¢ ì²˜ë¦¬ í›„ ê²°ì¸¡ì¹˜ ì´í•©: **{c_after}**")

    # EDA
    render_eda(df_reg, "íšŒê·€")

    # ëª¨ë¸ ì„¤ì •
    st.subheader("âš™ï¸ ëª¨ë¸ ì„¤ì • & í•™ìŠµ")
    with st.expander("êµìˆ˜ì ì„¤ëª…: íšŒê·€ë€?", expanded=True):
        st.markdown("""
**íšŒê·€(Regression)**ëŠ” **ì—°ì†ì ì¸ ìˆ˜ì¹˜**ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¬¸ì œì…ë‹ˆë‹¤.  
ì˜ˆ) ë‚ ì§œ/ìŠµë„/ë°”ëŒ ë“±ì˜ ì •ë³´ë¡œ **ê¸°ì˜¨**ì„ ì˜ˆì¸¡í•˜ê¸°.
        """)

    # ë‚ ì§œ íŒŒìƒë³€ìˆ˜ ì˜µì…˜
    if "date" in df_reg.columns and np.issubdtype(df_reg["date"].dtype, np.datetime64):
        add_time_feats = st.checkbox("ë‚ ì§œì—ì„œ íŒŒìƒë³€ìˆ˜ ì¶”ê°€(ì›”/ìš”ì¼)", True, key="reg_timefe")
        if add_time_feats:
            tmp = df_reg.copy()
            tmp["month"] = tmp["date"].dt.month
            tmp["weekday"] = tmp["date"].dt.weekday
            df_reg = tmp

    Xr, yr = build_xy(df_reg, target_reg)

    c1, c2, c3 = st.columns([1,1,1])
    with c1:
        test_size_r = st.slider("í…ŒìŠ¤íŠ¸ ë¹„ìœ¨", 0.1, 0.4, 0.2, step=0.05, key="reg_test")
    with c2:
        scale_num_r = st.checkbox("ìˆ«ìí˜• ìŠ¤ì¼€ì¼ë§(StandardScaler)", False, key="reg_scale")
    with c3:
        onehot_cat_r = st.checkbox("ë¬¸ìí˜• ì›-í•«ì¸ì½”ë”©", True, key="reg_ohe")

    model_name_r = st.selectbox("ëª¨ë¸ ì„ íƒ", ["LinearRegression", "Ridge", "Lasso", "KNN", "RandomForest"], key="reg_model")

    if model_name_r == "LinearRegression":
        mdl = LinearRegression()
    elif model_name_r == "Ridge":
        alpha = st.slider("alpha(ê·œì œ ì„¸ê¸°)", 0.01, 10.0, 1.0, 0.01, key="ridge_a")
        mdl = Ridge(alpha=alpha, random_state=42)
    elif model_name_r == "Lasso":
        alpha = st.slider("alpha(ê·œì œ ì„¸ê¸°)", 0.001, 1.0, 0.01, 0.001, key="lasso_a")
        mdl = Lasso(alpha=alpha, random_state=42, max_iter=5000)
    elif model_name_r == "KNN":
        k = st.slider("ì´ì›ƒ ìˆ˜(k)", 1, 30, 5, key="knn_k")
        mdl = KNeighborsRegressor(n_neighbors=k)
    else:
        n = st.slider("íŠ¸ë¦¬ ê°œìˆ˜", 50, 500, 200, 50, key="rf_n")
        depth = st.slider("ìµœëŒ€ ê¹Šì´(0=ì œí•œì—†ìŒ)", 0, 20, 0, key="rf_d")
        mdl = RandomForestRegressor(
            n_estimators=n,
            max_depth=None if depth==0 else depth,
            random_state=42
        )

    pre_r = make_preprocessor(Xr, scale_numeric=scale_num_r, onehot_categorical=onehot_cat_r)
    pipe_r = Pipeline([("pre", pre_r), ("model", mdl)]) if pre_r is not None else Pipeline([("model", mdl)])

    if st.button("ğŸŸ¢ í•™ìŠµ/í‰ê°€ ì‹¤í–‰", key="reg_train"):
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

        X_train, X_test, y_train, y_test = train_test_split(Xr, yr, test_size=test_size_r, random_state=42)
        pipe_r.fit(X_train, y_train)
        pred = pipe_r.predict(X_test)

        rmse = mean_squared_error(y_test, pred, squared=False)
        mae  = mean_absolute_error(y_test, pred)
        r2   = r2_score(y_test, pred)

        c1, c2, c3 = st.columns(3)
        c1.metric("RMSE(ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)", f"{rmse:.3f}")
        c2.metric("MAE(ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)", f"{mae:.3f}")
        c3.metric("RÂ²(ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)", f"{r2:.3f}")

        # ì˜ˆì¸¡ vs ì‹¤ì œ ì‚°ì ë„
        st.write("**ì˜ˆì¸¡ vs ì‹¤ì œ ì‚°ì ë„**")
        df_plot = pd.DataFrame({"y_true": y_test, "y_pred": pred})
        sc = alt.Chart(df_plot).mark_circle(size=60, opacity=0.6).encode(
            x=alt.X("y_true:Q", title="ì‹¤ì œê°’"),
            y=alt.Y("y_pred:Q", title="ì˜ˆì¸¡ê°’"),
            tooltip=["y_true","y_pred"]
        ).properties(height=350)
        # y=x ê¸°ì¤€ì„ 
        line_min = float(df_plot.min().min())
        line_max = float(df_plot.max().max())
        base_line = pd.DataFrame({"y": [line_min, line_max]})
        line = alt.Chart(base_line).mark_line().encode(x="y:Q", y="y:Q")
        st.altair_chart(sc + line, use_container_width=True)

        # ì”ì°¨ ë¶„í¬
        st.write("**ì”ì°¨(ì‹¤ì œ-ì˜ˆì¸¡) ë¶„í¬**")
        resid = y_test - pred
        df_res = pd.DataFrame({"residual": resid})
        hist = alt.Chart(df_res).mark_bar().encode(
            x=alt.X("residual:Q", bin=alt.Bin(maxbins=40)),
            y="count()"
        ).properties(height=300)
        st.altair_chart(hist, use_container_width=True)

        # ì‹œê³„ì—´ ë¹„êµ: dateê°€ ìˆìœ¼ë©´
        if "date" in df_reg.columns and np.issubdtype(df_reg["date"].dtype, np.datetime64):
            st.write("**ì‹œê³„ì—´ ë¹„êµ(í…ŒìŠ¤íŠ¸ì…‹)**")
            part = df_reg.loc[y_test.index, ["date"]].copy()
            part["y_true"] = y_test.values
            part["y_pred"] = pred
            part = part.sort_values("date")
            line_true = alt.Chart(part).mark_line().encode(
                x="date:T", y=alt.Y("y_true:Q", title="ê°’"), tooltip=["date","y_true"]
            )
            line_pred = alt.Chart(part).mark_line().encode(
                x="date:T", y="y_pred:Q", tooltip=["date","y_pred"]
            )
            st.altair_chart(line_true + line_pred, use_container_width=True)

# í‘¸í„°(êµìœ¡ ë©”ëª¨)
st.markdown("---")
st.markdown("""
**êµìœ¡ ë©”ëª¨**  
- **EDA ìš°ì„ **: ë°ì´í„° êµ¬ì¡°Â·ë¶„í¬Â·ê´€ê³„ë¥¼ ë¨¼ì € íŒŒì•…í•˜ë©´ ì „ì²˜ë¦¬ì™€ ëª¨ë¸ ì„ íƒì´ ì‰¬ì›Œì§‘ë‹ˆë‹¤.  
- **ë¶„ë¥˜**ëŠ” í´ë˜ìŠ¤(ë²”ì£¼) ì˜ˆì¸¡, **íšŒê·€**ëŠ” ì—°ì†ê°’ ì˜ˆì¸¡ì…ë‹ˆë‹¤.  
- ê²°ì¸¡ì¹˜ëŠ” **ì‹œê°„ë³´ê°„(ì‹œê³„ì—´)**, **ì¤‘ì•™ê°’ ëŒ€ì¹˜(ë²”ìš©)**ì²˜ëŸ¼ ë§¥ë½ì— ë§ê²Œ ì²˜ë¦¬í•˜ì„¸ìš”.  
- ì—…ë¡œë“œ CSVë„ ë™ì¼ íë¦„ìœ¼ë¡œ ì‹¤ìŠµí•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë¼ ìˆìŠµë‹ˆë‹¤.
""")
