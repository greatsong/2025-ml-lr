import os
import glob
import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

st.set_page_config(page_title="ğŸŒ¡ï¸ ì¼ì¼ EDA + ì—°í‰ê·  ì„ í˜•íšŒê·€(ì—°ë„)", layout="wide")

# =========================
# ìœ í‹¸: íŒŒì¼/CSV ë¡œë”©
# =========================
def find_latest_csv(search_dirs=("data", ".")):
    """
    search_dirs ìˆœì„œëŒ€ë¡œ íƒìƒ‰í•´ ê°€ì¥ ìµœì‹  ìˆ˜ì •(csv) íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜.
    ì—†ìœ¼ë©´ None.
    """
    candidates = []
    for d in search_dirs:
        if not os.path.isdir(d):
            continue
        candidates.extend(glob.glob(os.path.join(d, "*.csv")))
    if not candidates:
        return None
    # ìµœì‹  ìˆ˜ì •ì‹œê°„ ê¸°ì¤€ ì •ë ¬
    candidates.sort(key=lambda p: os.path.getmtime(p), reverse=True)
    return candidates[0]

def smart_read_csv(file_or_path, skip_top_rows=7):
    """
    cp949 â†’ utf-8-sig â†’ utf-8 â†’ euc-kr ìˆœìœ¼ë¡œ ì‹œë„.
    ìƒë‹¨ skip_top_rows(ê¸°ë³¸ 7í–‰) ìŠ¤í‚µ.
    """
    encodings = ["cp949", "utf-8-sig", "utf-8", "euc-kr"]
    for enc in encodings:
        try:
            return pd.read_csv(
                file_or_path,
                encoding=enc,
                skiprows=range(skip_top_rows) if skip_top_rows > 0 else None
            )
        except Exception:
            continue
    # ë§ˆì§€ë§‰ ì‹œë„(ì¸ì½”ë”© ì§€ì • ì—†ì´)
    return pd.read_csv(
        file_or_path,
        skiprows=range(skip_top_rows) if skip_top_rows > 0 else None
    )

def load_default_or_simulated(skip_top_rows=7):
    """
    data/ ë˜ëŠ” í˜„ì¬ í´ë”ì—ì„œ ìµœì‹  CSVë¥¼ ì°¾ì•„ ë¡œë“œ.
    ì—†ìœ¼ë©´ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±.
    """
    latest = find_latest_csv(("data", "."))
    if latest is not None:
        df = smart_read_csv(latest, skip_top_rows=skip_top_rows)
        return df, latest
    # ì‹œë®¬ë ˆì´ì…˜(í•˜ë£¨ ë‹¨ìœ„ 1ë…„)
    rng = np.random.default_rng(42)
    days = pd.date_range("2024-01-01", periods=365, freq="D")
    doy = np.arange(365)
    base = 15 + 10*np.sin(2*np.pi*(doy/365))
    noise = rng.normal(0, 1.5, 365)
    tavg = base + noise
    tmax = tavg + rng.normal(3, 0.7, 365)
    tmin = tavg - rng.normal(3, 0.7, 365)
    df = pd.DataFrame({"date": days, "tavg": tavg.round(2), "tmax": tmax.round(2), "tmin": tmin.round(2)})
    return df, "(simulated)"

# =========================
# ìœ í‹¸: ì—°í‰ê·  ê³„ì‚°(ì—°ë„ë³„)
# =========================
def compute_yearly_mean(df_daily, target_col, miss_threshold=0.02):
    """
    ì—°ë„ë³„ë¡œ target_colì˜ ì—°í‰ê· ì„ ê³„ì‚°.
    - í•œ í•´ì—ì„œ target_col ê²°ì¸¡ ë¹„ìœ¨ì´ miss_threshold(ê¸°ë³¸ 2%) ì´ˆê³¼ë©´ í•´ë‹¹ ì—°ë„ avg=NaNìœ¼ë¡œ ì²˜ë¦¬.
    """
    df = df_daily.copy()
    if "date" not in df.columns:
        raise ValueError("ë°ì´í„°ì— 'date' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    # ë‚ ì§œ íŒŒì‹±
    if not np.issubdtype(df["date"].dtype, np.datetime64):
        df["date"] = pd.to_datetime(df["date"], errors="coerce")
    df["year"] = df["date"].dt.year

    out = []
    for y, g in df.groupby("year", dropna=True):
        # target ì¡´ì¬ í™•ì¸
        if target_col not in g.columns:
            out.append({"year": y, "avg": np.nan})
            continue
        n_total = len(g)
        if n_total == 0:
            out.append({"year": y, "avg": np.nan})
            continue
        n_missing = g[target_col].isna().sum()
        miss_ratio = n_missing / n_total
        if miss_ratio > miss_threshold:
            avg_val = np.nan  # 2% ì´ˆê³¼ â†’ í•´ë‹¹ ì—°ë„ ì œì™¸
        else:
            avg_val = g[target_col].mean(skipna=True)
        out.append({"year": int(y), "avg": avg_val})
    df_year = pd.DataFrame(out).sort_values("year").reset_index(drop=True)
    return df_year

# =========================
# ì‚¬ì´ë“œë°”: ë°ì´í„° ì…ë ¥/ì˜µì…˜
# =========================
with st.sidebar:
    st.header("âš™ï¸ ë°ì´í„° & ì˜µì…˜")
    skip_n = st.slider("ìƒë‹¨ ìŠ¤í‚µ í–‰ ìˆ˜", 0, 20, 7,
                       help="ìš”ì²­: 1~7í–‰ì€ ë©”íƒ€/ì„¤ëª…ì¼ ìˆ˜ ìˆì–´ ê¸°ë³¸ 7í–‰ ìŠ¤í‚µ")
    src = st.radio("ë°ì´í„° ì†ŒìŠ¤", ["ê¸°ë³¸(ìµœì‹  CSV ìë™)", "CSV ì—…ë¡œë“œ"], horizontal=False)
    miss_threshold = st.number_input("ì—°ê°„ ê²°ì¸¡ ì„ê³„ê°’(ë¹„ìœ¨)", min_value=0.0, max_value=1.0, value=0.02, step=0.01,
                                     help="í•œ í•´ì˜ ê²°ì¸¡ ë¹„ìœ¨ì´ ì´ ê°’ì„ ì´ˆê³¼í•˜ë©´ í•´ë‹¹ ì—°ë„ëŠ” ì œì™¸")
    st.caption("ì¸ì½”ë”©ì€ cp949 â†’ utf-8-sig â†’ utf-8 â†’ euc-kr ìˆœìœ¼ë¡œ ìë™ ì‹œë„í•©ë‹ˆë‹¤.")

# =========================
# ë°ì´í„° ë¡œë“œ
# =========================
if src == "CSV ì—…ë¡œë“œ":
    up = st.file_uploader("CSV ì—…ë¡œë“œ (ê¶Œì¥: cp949)", type=["csv"])
    if up is None:
        st.info("CSVë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”. (ë˜ëŠ” ì‚¬ì´ë“œë°”ì—ì„œ 'ê¸°ë³¸'ì„ ì„ íƒ)")
        st.stop()
    df_daily = smart_read_csv(up, skip_top_rows=skip_n)
    loaded_from = "(uploaded)"
else:
    df_daily, loaded_from = load_default_or_simulated(skip_top_rows=skip_n)

st.success(f"ë°ì´í„° ì†ŒìŠ¤: **{loaded_from}**")

# ë‚ ì§œ íŒŒì‹±
if "date" not in df_daily.columns:
    st.error("ë°ì´í„°ì— 'date' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤. (YYYY-MM-DD ë“±)")
    st.dataframe(df_daily.head())
    st.stop()

try:
    df_daily["date"] = pd.to_datetime(df_daily["date"], errors="coerce")
except Exception:
    pass

# =========================
# EDA (ì¼ ë‹¨ìœ„)
# =========================
st.header("ğŸ“Š EDA â€” ì¼ ë‹¨ìœ„ ë°ì´í„°")
c1, c2, c3 = st.
