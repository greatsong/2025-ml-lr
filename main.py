import os
import glob
import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

st.set_page_config(page_title="ğŸŒ¡ï¸ ì¼ì¼ EDA + ì—°í‰ê·  ì„ í˜•íšŒê·€(ì—°ë„) + ë¯¸ë˜ì˜ˆì¸¡", layout="wide")

# =========================
# íŒŒì¼/CSV ë¡œë”© ìœ í‹¸
# =========================
def find_latest_csv(search_dirs=("data", ".")):
    """search_dirs ìˆœì„œëŒ€ë¡œ *.csvë¥¼ ëª¨ì•„ ê°€ì¥ ìµœê·¼ ìˆ˜ì • íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜. ì—†ìœ¼ë©´ None."""
    candidates = []
    for d in search_dirs:
        if not os.path.isdir(d):
            continue
        candidates.extend(glob.glob(os.path.join(d, "*.csv")))
    if not candidates:
        return None
    candidates.sort(key=lambda p: os.path.getmtime(p), reverse=True)
    return candidates[0]

def smart_read_csv(file_or_path, skip_top_rows=7):
    """cp949 â†’ utf-8-sig â†’ utf-8 â†’ euc-kr ìˆœìœ¼ë¡œ ì‹œë„. ìƒë‹¨ Ní–‰ ìŠ¤í‚µ."""
    encodings = ["cp949", "utf-8-sig", "utf-8", "euc-kr"]
    for enc in encodings:
        try:
            return pd.read_csv(
                file_or_path,
                encoding=enc,
                skiprows=range(skip_top_rows) if skip_top_rows > 0 else None
            )
        except Exception:
            continue
    # ë§ˆì§€ë§‰ ì‹œë„(ì¸ì½”ë”© ë¯¸ì§€ì •)
    return pd.read_csv(
        file_or_path,
        skiprows=range(skip_top_rows) if skip_top_rows > 0 else None
    )

def load_default_or_simulated(skip_top_rows=7):
    """data/ ë˜ëŠ” í˜„ì¬ í´ë”ì—ì„œ ìµœì‹  CSV ìë™ ë¡œë“œ. ì—†ìœ¼ë©´ ì‹œë®¬ë ˆì´ì…˜ ìƒì„±."""
    latest = find_latest_csv(("data", "."))
    if latest is not None:
        df = smart_read_csv(latest, skip_top_rows=skip_top_rows)
        return df, latest
    # ì‹œë®¬ë ˆì´ì…˜(1ë…„)
    rng = np.random.default_rng(42)
    days = pd.date_range("2024-01-01", periods=365, freq="D")
    doy = np.arange(365)
    base = 15 + 10*np.sin(2*np.pi*(doy/365))
    noise = rng.normal(0, 1.5, 365)
    tavg = base + noise
    tmax = tavg + rng.normal(3, 0.7, 365)
    tmin = tavg - rng.normal(3, 0.7, 365)
    df = pd.DataFrame({"date": days, "tavg": tavg.round(2), "tmax": tmax.round(2), "tmin": tmin.round(2)})
    return df, "(simulated)"

# =========================
# ì—°í‰ê·  ê³„ì‚°(ì—°ë„ë³„)
# =========================
def compute_yearly_mean(df_daily, target_col, miss_threshold=0.02):
    """
    ì—°ë„ë³„ë¡œ target_colì˜ ì—°í‰ê· ì„ ê³„ì‚°.
    - í•œ í•´ì—ì„œ target_col ê²°ì¸¡ ë¹„ìœ¨ì´ miss_threshold(ê¸°ë³¸ 2%) 'ì´ˆê³¼'ë©´ í•´ë‹¹ ì—°ë„ avg=NaN(ì œì™¸).
    """
    df = df_daily.copy()

    # ë‚ ì§œ ì •ê·œí™”/íŒŒì‹±
    if "date" not in df.columns:
        raise ValueError("date ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    if not np.issubdtype(df["date"].dtype, np.datetime64):
        df["date"] = pd.to_datetime(df["date"], errors="coerce")

    df["year"] = df["date"].dt.year

    out = []
    for y, g in df.groupby("year", dropna=True):
        if target_col not in g.columns or len(g) == 0:
            out.append({"year": int(y), "avg": np.nan})
            continue
        n_total = len(g)
        n_missing = g[target_col].isna().sum()
        miss_ratio = n_missing / n_total
        if miss_ratio > miss_threshold:
            avg_val = np.nan
        else:
            avg_val = g[target_col].mean(skipna=True)
        out.append({"year": int(y), "avg": avg_val})

    df_year = pd.DataFrame(out).sort_values("year").reset_index(drop=True)
    return df_year

# =========================
# ì‚¬ì´ë“œë°”: ì˜µì…˜
# =========================
with st.sidebar:
    st.header("âš™ï¸ ë°ì´í„° & ì˜µì…˜")
    skip_n = st.slider("ìƒë‹¨ ìŠ¤í‚µ í–‰ ìˆ˜", 0, 20, 7,
                       help="ìš”ì²­ì‚¬í•­: 1~7í–‰ì€ ë©”íƒ€/ì„¤ëª…ì¼ ìˆ˜ ìˆì–´ ê¸°ë³¸ 7í–‰ ìŠ¤í‚µ")
    src = st.radio("ë°ì´í„° ì†ŒìŠ¤", ["ê¸°ë³¸(ìµœì‹  CSV ìë™)", "CSV ì—…ë¡œë“œ"], horizontal=False)
    miss_threshold = st.number_input("ì—°ê°„ ê²°ì¸¡ ì„ê³„ê°’(ë¹„ìœ¨)", min_value=0.0, max_value=1.0, value=0.02, step=0.01,
                                     help="í•œ í•´ì˜ ê²°ì¸¡ ë¹„ìœ¨ì´ ì´ ê°’ì„ ì´ˆê³¼í•˜ë©´ í•´ë‹¹ ì—°ë„ëŠ” ì œì™¸")
    st.caption("ì¸ì½”ë”©ì€ cp949 â†’ utf-8-sig â†’ utf-8 â†’ euc-kr ìˆœìœ¼ë¡œ ìë™ ì‹œë„í•©ë‹ˆë‹¤.")

# =========================
# ë°ì´í„° ë¡œë“œ
# =========================
if src == "CSV ì—…ë¡œë“œ":
    up = st.file_uploader("CSV ì—…ë¡œë“œ (ê¶Œì¥: cp949)", type=["csv"])
    if up is None:
        st.info("CSVë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”. (ë˜ëŠ” ì‚¬ì´ë“œë°”ì—ì„œ 'ê¸°ë³¸'ì„ ì„ íƒ)")
        st.stop()
    df_daily = smart_read_csv(up, skip_top_rows=skip_n)
    loaded_from = "(uploaded)"
else:
    df_daily, loaded_from = load_default_or_simulated(skip_top_rows=skip_n)

st.success(f"ë°ì´í„° ì†ŒìŠ¤: **{loaded_from}**")

# === ë‚ ì§œ ì»¬ëŸ¼ëª… ì •ê·œí™”: 'ë‚ ì§œ' â†’ 'date' ===
if "date" not in df_daily.columns and "ë‚ ì§œ" in df_daily.columns:
    df_daily = df_daily.rename(columns={"ë‚ ì§œ": "date"})

# ë‚ ì§œ ì»¬ëŸ¼ í™•ì¸
if "date" not in df_daily.columns:
    st.error("ë°ì´í„°ì— 'date' (ë˜ëŠ” 'ë‚ ì§œ') ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    st.dataframe(df_daily.head())
    st.stop()

# ë‚ ì§œ íŒŒì‹±
try:
    df_daily["date"] = pd.to_datetime(df_daily["date"], errors="coerce")
except Exception:
    pass

# =========================
# EDA (ì¼ ë‹¨ìœ„)
# =========================
st.header("ğŸ“Š EDA â€” ì¼ ë‹¨ìœ„ ë°ì´í„°")
c1, c2, c3 = st.columns(3)
with c1:
    st.metric("í–‰(ì¼ ìˆ˜)", f"{len(df_daily):,}")
with c2:
    st.metric("ì—´(íŠ¹ì„± ìˆ˜)", f"{df_daily.shape[1]:,}")
with c3:
    st.metric("ê²°ì¸¡ ì´í•©", f"{int(df_daily.isna().sum().sum()):,}")

with st.expander("ë°ì´í„° íƒ€ì… / ê²°ì¸¡ì¹˜ ìš”ì•½", expanded=False):
    st.write("**ë°ì´í„° íƒ€ì…**")
    st.dataframe(pd.DataFrame(df_daily.dtypes, columns=["dtype"]))
    st.write("**ê²°ì¸¡ì¹˜ í•©ê³„(ì—´ë³„)**")
    miss = df_daily.isna().sum()
    miss_df = miss[miss > 0].to_frame("missing_count")
    if miss_df.empty:
        st.success("ê²°ì¸¡ì¹˜ ì—†ìŒ âœ…")
    else:
        st.dataframe(miss_df)

# ìˆ«ìí˜• í›„ë³´ ë° ê¸°ë³¸ ê¸°ì˜¨ ì»¬ëŸ¼ ì¶”ì •
num_cols = df_daily.select_dtypes(include=np.number).columns.tolist()
heuristic_order = ["tavg", "temp", "tmean", "avg_temp", "tmax", "tmin", "í‰ê· ê¸°ì˜¨", "ìµœê³ ê¸°ì˜¨", "ìµœì €ê¸°ì˜¨"]
default_targets = [c for c in heuristic_order if c in num_cols]
default_show = default_targets[:2] if default_targets else (num_cols[:2] if len(num_cols) >= 2 else num_cols)

st.subheader("ì¼ ë‹¨ìœ„ ë¼ì¸ ì°¨íŠ¸")

# ì‚¬ìš©ì ì •ì˜ ìƒ‰ìƒ ë§µ: tmax=red, tavgê³„ì—´=green, tmin=blue (+í•œê¸€ëª… í¬í•¨)
base_color_map = {
    "tmax": "red", "ìµœê³ ê¸°ì˜¨": "red",
    "tavg": "green", "temp": "green", "tmean": "green", "avg_temp": "green", "í‰ê· ê¸°ì˜¨": "green",
    "tmin": "blue", "ìµœì €ê¸°ì˜¨": "blue"
}

eda_cols = st.multiselect("í‘œì‹œí•  ê¸°ì˜¨(ìˆ«ìí˜•) ì»¬ëŸ¼", options=num_cols, default=default_show)
if eda_cols:
    df_melt = df_daily[["date"] + eda_cols].melt("date", var_name="metric", value_name="value")
    present_metrics = df_melt["metric"].unique().tolist()
    domain, range_colors = [], []
    for m in present_metrics:
        if m in base_color_map:
            domain.append(m); range_colors.append(base_color_map[m])
    color_encoding = alt.Color("metric:N")
    if domain and len(domain) == len(range_colors):
        color_encoding = alt.Color("metric:N", scale=alt.Scale(domain=domain, range=range_colors))

    line = alt.Chart(df_melt).mark_line().encode(
        x="date:T",
        y=alt.Y("value:Q", title="ê°’"),
        color=color_encoding,
        tooltip=["date:T", "metric:N", alt.Tooltip("value:Q", format=".2f")]
    ).properties(height=320)
    st.altair_chart(line, use_container_width=True)
else:
    st.info("í‘œì‹œí•  ìˆ«ìí˜•(ê¸°ì˜¨) ì»¬ëŸ¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")

# =========================
# ì—°í‰ê·  íšŒê·€ (ì—°ë„ ë‹¨ìœ„)
# =========================
st.header("ğŸ“ˆ ì—°í‰ê·  ì„ í˜• íšŒê·€ â€” X=ì—°ë„, Y=ì„ íƒì§€í‘œ(ì—°í‰ê· )")

# íšŒê·€ íƒ€ê¹ƒ ì„ íƒ(í‰ê· /ìµœì €/ìµœê³  ì¤‘ íƒ1ì´ ìì—°ìŠ¤ëŸ¬ì›€)
target_choices = [c for c in ["tavg", "temp", "tmean", "avg_temp", "í‰ê· ê¸°ì˜¨", "tmax", "ìµœê³ ê¸°ì˜¨", "tmin", "ìµœì €ê¸°ì˜¨"] if c in num_cols]
if not target_choices:
    target_choices = num_cols
if not target_choices:
    st.error("ì—°í‰ê·  ëŒ€ìƒì´ ë  ìˆ«ìí˜• ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    st.stop()
target_col = st.selectbox("ì—°í‰ê· ìœ¼ë¡œ ì‚¬ìš©í•  ê¸°ì˜¨ ì§€í‘œ", options=target_choices, index=0)

# ì—°í‰ê·  ê³„ì‚°(2% ê·œì¹™ ê¸°ë³¸)
df_year = compute_yearly_mean(df_daily, target_col=target_col, miss_threshold=miss_threshold)

with st.expander("ì—°ë„ë³„ ê²°ì¸¡ ë¹„ìœ¨ ë¡œê·¸(ì •ë³´)", expanded=False):
    df_tmp = df_daily.copy()
    df_tmp["year"] = df_tmp["date"].dt.year
    logs = []
    for y, g in df_tmp.groupby("year", dropna=True):
        n_total = len(g)
        n_miss = g[target_col].isna().sum() if target_col in g.columns else np.nan
        r = (n_miss / n_total) if n_total else np.nan
        logs.append({"year": int(y), "days": n_total, "missing": int(n_miss) if pd.notna(n_miss) else np.nan, "missing_ratio": r})
    st.dataframe(pd.DataFrame(logs).sort_values("year"))

st.subheader("ì—°í‰ê·  í…Œì´ë¸”(ê²°ì¸¡ ì—°ë„ í¬í•¨)")
st.dataframe(df_year)

# íšŒê·€ì— ì‚¬ìš©í•  ë°ì´í„°(ê²°ì¸¡ ì—°ë„ ì œê±°)
df_fit = df_year.dropna(subset=["avg"]).copy()

if len(df_fit) < 3:
    st.warning("ì—°í‰ê·  ìœ íš¨ ì—°ë„ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤(ìµœì†Œ 3ë…„ ê¶Œì¥). ë°ì´í„°/ê²°ì¸¡ ì„ê³„ê°’ì„ í™•ì¸í•˜ì„¸ìš”.")
else:
    # Train/Test ë¶„í•  (ì—°ë„ ìˆ˜ê°€ ì ì„ ìˆ˜ ìˆì–´ ìµœì†Œ 1ê°œ í…ŒìŠ¤íŠ¸ í™•ë³´)
    test_size_ratio = max(1, int(len(df_fit) * 0.2)) / len(df_fit)
    X = df_fit[["year"]]  # X=ì—°ë„
    y = df_fit["avg"]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_ratio, random_state=42)

    model = LinearRegression()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # í˜¸í™˜ì„±: RMSE = sqrt(MSE)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))

    c1, c2, c3 = st.columns(3)
    with c1:
        st.metric("í›ˆë ¨ ìƒ˜í”Œ(ì—°ë„)", f"{len(X_train)}")
    with c2:
        st.metric("í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ(ì—°ë„)", f"{len(X_test)}")
    with c3:
        st.metric("RMSE (í…ŒìŠ¤íŠ¸)", f"{rmse:.3f}")

    a = float(model.coef_[0])
    b = float(model.intercept_)
    st.caption(f"íšŒê·€ì‹: **avg â‰ˆ {a:.4f} Ã— year + {b:.4f}**")

    # ì „ì²´ ì—°ë„ì— ëŒ€í•œ ì˜ˆì¸¡ì„ (ê³¼ê±° ë°ì´í„° ë²”ìœ„)
    df_fit["pred"] = model.predict(df_fit[["year"]])

    base_chart = (
        alt.Chart(df_fit).mark_circle(size=70, opacity=0.85).encode(
            x=alt.X("year:O", title="ì—°ë„"),
            y=alt.Y("avg:Q", title=f"ì—°í‰ê·  {target_col}"),
            tooltip=["year:O", alt.Tooltip("avg:Q", format=".2f")]
        )
        + alt.Chart(df_fit).mark_line(color="black").encode(
            x="year:O",
            y="pred:Q"
        )
    ).properties(height=360)

    # =========================
    # ğŸ”® ë¯¸ë˜ ì˜ˆì¸¡ UI/ë¡œì§
    # =========================
    st.subheader("ğŸ”® ë¯¸ë˜ ì˜ˆì¸¡")

    # 'ì™„ì „í•œ ë§ˆì§€ë§‰ ì—°ë„' ê³„ì‚°: ìµœì‹  ë‚ ì§œê°€ ê·¸ í•´ì˜ 12ì›” 31ì¼ ì´ìƒì´ë©´ ê·¸ í•´ê°€ ì™„ì „, ì•„ë‹ˆë©´ ê·¸ ì „í•´
    max_dt = df_daily["date"].dropna().max()
    if pd.isna(max_dt):
        st.info("ë‚ ì§œ ë°ì´í„°ê°€ ì—†ì–´ ë¯¸ë˜ ì˜ˆì¸¡ ë²”ìœ„ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.altair_chart(base_chart, use_container_width=True)
    else:
        last_day_of_year = pd.Timestamp(max_dt.year, 12, 31)
        last_complete_year = max_dt.year if max_dt >= last_day_of_year else (max_dt.year - 1)

        # ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì‹œì‘ ì—°ë„ = ì™„ì „í•œ ë§ˆì§€ë§‰ ì—°ë„ + 1
        start_pred_year = max(last_complete_year + 1, int(df_fit["year"].min()) if len(df_fit) else last_complete_year + 1)
        start_pred_year = min(start_pred_year, 2100)  # ìƒí•œ ë³´í˜¸

        if start_pred_year > 2100:
            st.warning("ì˜ˆì¸¡ ì‹œì‘ ì—°ë„ê°€ 2100ì„ ì´ˆê³¼í•©ë‹ˆë‹¤. ë” ìµœê·¼ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            st.altair_chart(base_chart, use_container_width=True)
        else:
            # ë‹¨ì¼ ì—°ë„ ì˜ˆì¸¡
            year_to_predict = st.number_input(
                "ì˜ˆì¸¡í•  ë‹¨ì¼ ì—°ë„",
                min_value=int(start_pred_year), max_value=2100,
                value=int(min(start_pred_year + 5, 2100)), step=1
            )
            if st.button("í•´ë‹¹ ì—°ë„ ì˜ˆì¸¡"):
                pred_single = float(model.predict([[year_to_predict]])[0])
                st.success(f"ğŸ“Œ {year_to_predict}ë…„ ì˜ˆìƒ {target_col} = **{pred_single:.2f}**")

            # êµ¬ê°„ ì˜ˆì¸¡(ìŠ¬ë¼ì´ë”): [start_pred_year, 2100]
            yr_min = int(start_pred_year)
            yr_max = 2100
            default_hi = min(yr_min + 20, yr_max)
            yr_range = st.slider("ì˜ˆì¸¡ êµ¬ê°„(ì—°ë„ ë²”ìœ„)", min_value=yr_min, max_value=yr_max, value=(yr_min, default_hi), step=1)

            future_years = pd.DataFrame({"year": list(range(yr_range[0], yr_range[1] + 1))})
            future_years["pred"] = model.predict(future_years[["year"]])

            # ì ì„ ìœ¼ë¡œ ë¯¸ë˜ êµ¬ê°„ ì˜ˆì¸¡ì„  ì˜¤ë²„ë ˆì´
            chart_future = alt.Chart(future_years).mark_line(strokeDash=[5,5], color="gray").encode(
                x=alt.X("year:O", title="ì—°ë„"),
                y=alt.Y("pred:Q", title=f"ì—°í‰ê·  {target_col} (ì˜ˆì¸¡)")
            )

            st.altair_chart(base_chart + chart_future, use_container_width=True)

            with st.expander("ì˜ˆì¸¡ í…Œì´ë¸” ë³´ê¸°", expanded=False):
                st.dataframe(future_years)

# í‘¸í„°: êµìœ¡ ë©”ëª¨
st.markdown("---")
st.markdown("""
**êµìœ¡ ë©”ëª¨**  
- EDAëŠ” **ì¼ ë‹¨ìœ„**ë¡œ íŒ¨í„´/ì´ìƒì¹˜ë¥¼ ë¨¼ì € í™•ì¸í•©ë‹ˆë‹¤.  
- ëª¨ë¸ë§ì€ **ì—°í‰ê· (ì—°ë„ ë‹¨ìœ„)**ë¡œ ì¶•ì•½í•´ **ì¥ê¸° ì¶”ì„¸**ë¥¼ ê°„ë‹¨í•œ ì„ í˜•íšŒê·€ë¡œ ì‚´í´ë´…ë‹ˆë‹¤.  
- í•œ í•´ì˜ ê²°ì¸¡ì´ ì¼ì • ë¹„ìœ¨(ê¸°ë³¸ 2%)ì„ ë„˜ìœ¼ë©´ **í•´ë‹¹ ì—°ë„ë¥¼ ì œì™¸**í•´ ë°ì´í„° í’ˆì§ˆì„ í™•ë³´í•©ë‹ˆë‹¤.  
- ì˜ˆì¸¡ì€ **ì™„ì „í•œ ë§ˆì§€ë§‰ ì—°ë„ ë‹¤ìŒ í•´ë¶€í„°** 2100ë…„ê¹Œì§€ë¡œ ì œí•œí•©ë‹ˆë‹¤(ë¶€ë¶„ ì—°ë„ëŠ” ë¶ˆì™„ì „ ë°ì´í„°ë¡œ ê°„ì£¼).
""")
